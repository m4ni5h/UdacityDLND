# UdacityDLND
Repository for Udacity Deep Learning Program

# Links 1. Introduction to Deep Learning
- http://cs231n.github.io/convolutional-networks/
- https://www.manning.com/books/grokking-deep-learning
- https://github.com/iamtrask/Grokking-Deep-Learning
- https://en.wikipedia.org/wiki/Word2vec
- https://github.com/junyanz/CycleGAN
- https://www.csail.mit.edu/
- https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
- https://aws.amazon.com/sagemaker/
- https://www.udacity.com/course/programming-foundations-with-python--ud036
- https://www.khanacademy.org/math/multivariable-calculus
- https://www.khanacademy.org/math/linear-algebra
- https://www.udacity.com/course/intro-to-data-analysis--ud170
- https://www.udacity.com/get-hired
- https://udacity.zendesk.com/hc/en-us
- https://udacity.zendesk.com/hc/en-us/requests/new?ticket_form_id=110806
- https://anaconda.org/
- https://docs.continuum.io/mkl-optimizations/
- https://www.crummy.com/software/BeautifulSoup/
- http://www.yaml.org/
- http://docs.getpelican.com/en/stable/
- https://jakevdp.github.io/blog/2016/08/25/conda-myths-and-misconceptions/
- https://docs.conda.io/projects/conda
- https://docs.conda.io/projects/conda/en/latest/user-guide/cheatsheet.html
- https://wiki.python.org/moin/Python2orPython3
- https://github.com/lengstrom/fast-style-transfer
- https://www.youtube.com/watch?v=xVJwwWQlQ1o
- https://github.com/lengstrom/fast-style-transfer/tree/master/examples/style
- https://drive.google.com/drive/folders/0B9jhaT37ydSyRk9UX0wwX3BpMzQ
- https://d17h27t6h515a5.cloudfront.net/topher/2017/January/587d1865_rain-princess/rain-princess.ckpt
- http://video.udacity-data.com.s3.amazonaws.com/topher/2017/January/587d1865_rain-princess/rain-princess.ckpt
- http://video.udacity-data.com.s3.amazonaws.com/topher/2017/January/588aa800_la-muse/la-muse.ckpt
- http://video.udacity-data.com.s3.amazonaws.com/topher/2017/January/588aa846_udnie/udnie.ckpt
- http://video.udacity-data.com.s3.amazonaws.com/topher/2017/January/588aa883_scream/scream.ckpt
- http://video.udacity-data.com.s3.amazonaws.com/topher/2017/January/588aa89d_wave/wave.ckpt
- http://video.udacity-data.com.s3.amazonaws.com/topher/2017/January/588aa8b6_wreck/wreck.ckpt
- https://twitter.com/cezannecam
- https://selfdrivingcars.mit.edu/deeptraffic/
- https://en.wikipedia.org/wiki/Reinforcement_learning
- https://selfdrivingcars.mit.edu/deeptraffic/
- https://github.com/yenchenlin/DeepLearningFlappyBird
- https://www.manning.com/books/grokking-deep-learning
- http://neuralnetworksanddeeplearning.com/
- http://www.deeplearningbook.org/

## Jupyter Notebook Links
- http://jupyter.org/
- https://losc.ligo.org/s/events/GW150914/GW150914_tutorial.html
- https://www.ligo.caltech.edu/news/ligo20160211
- http://nbviewer.jupyter.org/github/jmsteinw/Notebooks/blob/master/IndeedJobs.ipynb
- http://nbviewer.jupyter.org/github/masinoa/machine_learning/blob/master/04_Neural_Networks.ipynb
- http://nbviewer.jupyter.org/github/tdhopper/rta-pyspark-presentation/blob/master/slides.ipynb
- https://github.com/mcleonard/blog_posts/blob/master/body_fat_percentage.ipynb
- http://nbviewer.jupyter.org/
- http://www.literateprogramming.com/
- http://www.witheve.com/
- https://ipython.org/
- https://www.r-project.org/
- http://julialang.org/
- https://github.com/jupyter/jupyter/wiki/Jupyter-kernels
- http://jupyter-notebook.readthedocs.io/en/latest/public_server.html
- http://localhost:8888/
- https://ipyparallel.readthedocs.io/en/latest/intro.html
- https://daringfireball.net/projects/markdown/
- http://docutils.sourceforge.net/rst.html
- http://video.udacity-data.com.s3.amazonaws.com/topher/2016/December/58474202_working-with-code-cells/working-with-code-cells.ipynb
- https://daringfireball.net/projects/markdown/basics
- https://www.latex-project.org/
- https://www.latex-tutorial.com/
- https://www.latex-tutorial.com/tutorials/
- https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet
- http://video.udacity-data.com.s3.amazonaws.com/topher/2017/April/58e412d0_keyboard-shortcuts/keyboard-shortcuts.ipynb
- http://matplotlib.org/faq/usage_faq.html#what-is-a-backend
- https://docs.python.org/3/library/pdb.html
- http://ipython.readthedocs.io/en/stable/interactive/magics.html
- https://nbconvert.readthedocs.io/en/latest/usage.html
- http://nbviewer.jupyter.org/format/slides/github/jorisvandenbossche/2015-PyDataParis/blob/master/pandas_introduction.ipynb#/
- https://nbviewer.jupyter.org/github/jorisvandenbossche/2015-PyDataParis/blob/master/pandas_introduction.ipynb

## Numpy
- https://docs.scipy.org/doc/numpy/reference/
- https://docs.scipy.org/doc/numpy/reference/arrays.scalars.html
- https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences
- https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html
- https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html

## Backpropagation
- http://neuralnetworksanddeeplearning.com/chap2.html
- https://www.youtube.com/watch?v=59Hbtz7XgjM (CS231n Winter 2016 Lecture 4 Backpropagation, Neural Networks)
- https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b#.vt3ax2kg9

## Loss function for gradient descent (Minimize error) (Neural Network Backpropagation)
- https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
- https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html
- https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy (Cross-entropy loss, or log loss)
- https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#mse-l2
- git clone https://github.com/udacity/deep-learning-v2-pytorch.git
- Gradient(https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient)
- https://distill.pub/2017/momentum/
- https://stats.idre.ucla.edu/stat/data/binary.csv
- https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/vectors/v/vector-introduction-linear-algebra
- https://www.khanacademy.org/math/precalculus/precalc-matrices
- https://video.udacity-data.com/topher/2019/October/5da05a3f_dlnd-p1-lessons-cheat-sheet-1/dlnd-p1-lessons-cheat-sheet-1.pdf
- https://www.youtube.com/watch?v=ht6fLrar91U (AI, Deep Learning, and Machine Learning: A Primer)

## Pytorch
- https://research.fb.com/category/facebook-ai-research-fair/
- https://pytorch.org/get-started/locally/
- 


## CNNs
- https://deepmind.com/blog/wavenet-generative-model-raw-audio/
- http://www.creativeai.net/posts/W2C3baXvf2yJSLbY6/a-neural-parametric-singing-synthesizer
- http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/
- https://www.getrevue.co/profile/wildml
- https://code.facebook.com/posts/1978007565818999/a-novel-approach-to-neural-machine-translation/
- https://deepmind.com/research/dqn/
- https://sites.google.com/a/deepmind.com/dqn/
- http://karpathy.github.io/2016/05/31/rl/
- https://quickdraw.withgoogle.com/#
- https://aiexperiments.withgoogle.com/
- https://www.autodraw.com/
- https://deepmind.com/research/alphago/
- https://www.technologyreview.com/s/604273/finding-solace-in-defeat-by-artificial-intelligence/?set=604287
- https://www.youtube.com/watch?v=AMDiR61f86Y
- http://www.droneomega.com/gps-drone-navigation-works/
- https://www.youtube.com/watch?v=wSFYOw4VIYY
- https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd013
- http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset
- https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project
- https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009
- http://ufldl.stanford.edu/housenumbers/
- https://github.com/udacity/machine-learning/tree/master/projects/digit_recognition
- https://pythonprogramming.net/game-frames-open-cv-python-plays-gta-v/
- http://www.businessinsider.com/3d-printed-works-of-art-for-the-blind-2016-1
- https://www.cs.nyu.edu/~deigen/depth/
- https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html
- https://blogs.nvidia.com/blog/2016/11/04/saving-endangered-species/?adbsc=social_20170303_70517416
- http://www.digitaltrends.com/photography/faceapp-neural-net-image-editing/
- https://twitter.com/cezannecam
- https://www.kaggle.com/benhamner/popular-datasets-over-time
- https://nips.cc/
- https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-torch-tensor
- http://mathworld.wolfram.com/GaussianFunction.html
- https://pytorch.org/docs/stable/nn.html#crossentropyloss
- https://pytorch.org/docs/stable/nn.html#nllloss
- https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf (first research paper to propose dropout as a technique for overfitting.)
- http://cs231n.github.io/neural-networks-1/#actfun (more information on activation functions)
- http://yann.lecun.com/exdb/mnist/
- http://setosa.io/ev/image-kernels/
- https://pytorch.org/docs/stable/nn.html#avgpool2d
- https://cezannec.github.io/Capsule_Networks/
- https://github.com/cezannec/capsule_net_pytorch
- https://video.udacity-data.com/topher/2018/November/5bfdca4f_dynamic-routing/dynamic-routing.pdf
- https://www.youtube.com/watch?v=pPN8d0E3900&list=PLuTYjXW7aAt3HLCATBOkkXtifCVAm0O_A (Aurélien Géron's Video)
- http://blog.kaggle.com/2015/01/02/cifar-10-competition-winners-interviews-with-dr-ben-graham-phil-culliton-zygmunt-zajac/
- http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf (AlexNet)
- https://arxiv.org/pdf/1409.1556.pdf (VGGNet)
- https://arxiv.org/pdf/1512.03385v1.pdf (ResNet)
- https://keras.io/applications/ (Keras documentation for famous CNN Arch)
- http://neuralnetworksanddeeplearning.com/chap5.html (Vanishing Gradient)
- https://github.com/jcjohnson/cnn-benchmarks (CNN Arch Benchmark)
- http://www.image-net.org/challenges/LSVRC/ (ImageNet ILSVRC)

## CNNs COOL STUFFs Visualizing CNNs
- http://cs231n.github.io/understanding-cnn/ Stanford's CS231n course on visualizing what CNN
- https://aiexperiments.withgoogle.com/what-neural-nets-see 
- http://openframeworks.cc/
- https://www.youtube.com/watch?v=AgkfIQ4IGaM&t=78s
- https://www.youtube.com/watch?v=ghEmQSxT6tw&t=5s
- https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html
- https://www.youtube.com/watch?v=XatXy6ZhKZw
- https://deepdreamgenerator.com/
- https://blog.openai.com/adversarial-example-research/
- https://arxiv.org/abs/1611.03530
- https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf
- https://www.youtube.com/watch?v=ghEmQSxT6tw

## Transfer Learning
- https://arxiv.org/pdf/1411.1792.pdf
- http://www.nature.com/articles/nature21056.epdf?referrer_access_token=_snzJ5POVSgpHutcNN4lEtRgN0jAjWel9jnR3ZoTv0NXpMHRAJy8Qn10ys2O4tuP9jVts1q2g1KBbk3Pd3AelZ36FalmvJLxw1ypYW0UxU7iShiMp86DmQ5Sh3wOBhXDm9idRXzicpVoBBhnUsXHzVUdYCPiVV0Slqf-Q25Ntb1SX_HAv3aFVSRgPbogozIHYQE3zSkyIghcAppAjrIkw1HtSwMvZ1PXrt6fVYXt-dvwXKEtdCN8qEHg0vbfl4_m&tracking_referrer=edition.cnn.com

## Weight Initialization
- http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf Understanding the difficulty of training deep feedforward neural networks
- https://arxiv.org/pdf/1502.01852v1.pdf Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification
- https://arxiv.org/pdf/1502.03167v2.pdf Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

## Style Transfer
- https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf

## RNN
- https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning
- https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html
- https://en.wikipedia.org/wiki/Vanishing_gradient_problem	 Vanishing Gradient
- https://socratic.org/algebra/exponents-and-exponential-functions/geometric-sequences-and-exponential-functions	 Geometric Series
- https://en.wikipedia.org/wiki/Time_delay_neural_network	 TDNN
- http://onlinelibrary.wiley.com/doi/10.1207/s15516709cog1402_1/abstract	 Elman Network
- https://en.wikipedia.org/wiki/Recurrent_neural_network#Elman_networks_and_Jordan_networks	 additional info
- http://www.bioinf.jku.at/publications/older/2604.pdf	 LSTM
- https://en.wikipedia.org/wiki/Sepp_Hochreiter	 Sepp Hochreiter
- http://people.idsia.ch/~juergen/	 Jürgen Schmidhuber
- https://deeplearning4j.org/lstm.html	 blog

## RNN Applications
- https://blog.openai.com/dota-2/	 DotA 2 bot by Open AI
- https://www.youtube.com/watch?time_continue=1&v=0FW99AQmMc8	 automatically adding sounds to silent movies?
- http://www.cs.toronto.edu/~graves/handwriting.cgi?text=My+name+is+Luka&style=&bias=0.15&samples=3	 automatic handwriting generation
- https://aws.amazon.com/lex/faqs/	 Amazon Lex
- https://code.facebook.com/posts/1827693967466780/building-an-efficient-neural-language-model-over-a-billion-words/	 building language models
- https://arxiv.org/pdf/1511.06939.pdf	 here is an interesting read

## Feed Forward
- http://linear.ups.edu/html/section-LC.html	 Linear Combination
- https://en.wikipedia.org/wiki/Matrix_multiplication	 Matrix Multiplication
- https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions	 here
- https://en.wikipedia.org/wiki/Mean_squared_error	 Mean Squared Error (MSE)
- https://www.ics.uci.edu/~pjsadows/notes.pdf	 cross entropy
- As a reminder, the two Error functions most commonly used are the Mean Squared Error (MSE) (usually used in regression problems) and the cross entropy (often used in classification problems).

## Backpropagation Theory
-	http://www.columbia.edu/itc/sipa/math/calc_rules_multivar.html	 Partial Derivatives
-	http://tutorial.math.lamar.edu/pdf/Common_Derivatives_Integrals.pdf	 common derivatives
-	http://blog.datumbox.com/tuning-the-learning-rate-in-gradient-descent/	 Tuning the learning rate resource 1
-	http://cs231n.github.io/neural-networks-3/#loss	 Tuning the learning rate resource 2

## RNN Implementation
-	http://onlinelibrary.wiley.com/doi/10.1207/s15516709cog1402_1/abstract	 Elman Network
-	https://en.wikipedia.org/wiki/Recurrent_neural_network#Elman_networks_and_Jordan_networks	 additional info

- https://arxiv.org/abs/1211.5063 gradient clipping

## RNN to LSTM
- http://www.bioinf.jku.at/publications/older/2604.pdf	 (LSTM)
- https://en.wikipedia.org/wiki/Sepp_Hochreiter	 Sepp Hochreiter
- http://people.idsia.ch/~juergen/	 Jürgen Schmidhuber

## Intro to LSTM
-	http://colah.github.io/posts/2015-08-Understanding-LSTMs/	 Chris Olah's LSTM post
-	http://blog.echen.me/2017/05/30/exploring-lstms/	 Edwin Chen's LSTM post
-	https://www.youtube.com/watch?v=iX5V1WpxxkY	 Andrej Karpathy's lecture
- http://www.cs.toronto.edu/~guerzhoy/321/lec/W09/rnn_gated.pdf
- https://pytorch.org/docs/stable/nn.html#recurrent-layers

## Character Level LSTM
- http://karpathy.github.io/2015/05/21/rnn-effectiveness/
- https://github.com/karpathy/char-rnn
- https://pytorch.org/docs/stable/torch.html#torch.topk
- https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html


## HyperParameters
- http://jalammar.github.io/

### Optimizer Hyperparameters
- Learning rate
- Minibatch size
- Epochs  {Early Stopping}
### Model Hyperparameters
- Number of layers {Dropout, L2 Regularization}
- Model structure variables
### Exponential Decay of Learning rate
-	https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay	 
### Adaptive Learning Optimizers
-	https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer	 AdamOptimizer
-	https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer	 AdagradOptimizer

### Epochs
- 	https://www.tensorflow.org/get_started/monitors#early_stopping_with_validationmonitor	 ValidationMonitor with tf.contrib.learn
- 	https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook	 SessionRunHooks
- 	https://www.tensorflow.org/api_guides/python/train#Training_Hooks	 training hooks
- 	https://www.tensorflow.org/api_docs/python/tf/train/StopAtStepHook	 StopAtStepHook
- 	https://www.tensorflow.org/api_docs/python/tf/train/NanTensorHook	 NanTensorHook

### Number of Layers/Units
- https://cs231n.github.io/neural-networks-1/   Andrej Karpathy
- http://www.deeplearningbook.org/contents/ml.html	 Deep Learning book	 chapter 5.2

### RNN Hyperparameters
- 	https://arxiv.org/abs/1412.3555	 Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling	
- 	http://proceedings.mlr.press/v37/jozefowicz15.pdf	 Jozefowicz	 et al. (2015)
- 	https://arxiv.org/abs/1506.02078	 Visualizing and Understanding Recurrent Networks	
- 	https://arxiv.org/pdf/1503.04069.pdf	 Greff	 et al. (2015)
- 	https://colah.github.io/posts/2015-08-Understanding-LSTMs/	 Understanding LSTM Networks	
- 	https://arxiv.org/abs/1703.03906v2	 Massive Exploration of Neural Machine Translation Architectures	
- 	https://arxiv.org/abs/1610.09975	 Speech Recognition (large vocabulary)	
- 	https://arxiv.org/abs/1303.5778	 Speech Recognition	
- 	https://arxiv.org/abs/1409.3215	 Machine Translation (seq2seq)	
- 	https://arxiv.org/abs/1411.4555	 Image Captioning	
- 	https://arxiv.org/abs/1502.04623	 Image Generation	
- 	http://www.aclweb.org/anthology/P15-2116	 Question Answering	
- 	https://pdfs.semanticscholar.org/3fbc/45152f20403266b02c4c2adab26fb367522d.pdf	 Text Summarization	

### Source and References
- 	https://arxiv.org/abs/1206.5533	 Practical recommendations for gradient-based training of deep architectures
- 	http://www.deeplearningbook.org/contents/guidelines.html	 Deep Learning book - chapter 11.4: Selecting Hyperparameters
- 	http://neuralnetworksanddeeplearning.com/chap3.html#how_to_choose_a_neural_network's_hyper-parameters	 Neural Networks and Deep Learning book - Chapter 3: How to choose a neural network's hyper-parameters?
- 	http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf	 Efficient BackProp (pdf)
- 	https://arxiv.org/abs/1507.05523	 How to Generate a Good Word Embedding?
- 	https://arxiv.org/abs/1606.02228	 Systematic evaluation of CNN advances on the ImageNet
- 	https://arxiv.org/abs/1506.02078	 Visualizing and Understanding Recurrent Networks

## Embeddings and Word2Vec
- https://video.udacity-data.com/topher/2018/October/5bc56d28_word2vec-mikolov/word2vec-mikolov.pdf
- https://video.udacity-data.com/topher/2018/October/5bc56da8_distributed-representations-mikolov2/distributed-representations-mikolov2.pdf
-	https://en.wikipedia.org/wiki/Word2vec	 Word2Vec algorithm
-	http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/	 conceptual overview
-	https://arxiv.org/pdf/1301.3781.pdf	 Mikolov et al.
-	http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf	 Neural Information Processing Systems
-	https://s3.amazonaws.com/video.udacity-data.com/topher/2018/October/5bbe6499_text8/text8.zip	 text8 dataset
-	https://pytorch.org/docs/stable/nn.html#embedding	 embedding layer
-	http://colah.github.io/posts/2014-10-Visualizing-MNIST/	 this post from Christopher Olah
- https://pytorch.org/docs/master/notes/extending.html


## Attention
- https://arxiv.org/abs/1409.0473   Neural Machine Translation by Jointly Learning to Align and Translate (Additive/Bahdanau Attention)
- https://arxiv.org/abs/1508.04025  Effective Approaches to Attention-based Neural Machine Translation (Multiplicative/Luong Attention)

